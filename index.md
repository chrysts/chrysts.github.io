# 2025 Progress Bar (48%)
![img](https://pbs.twimg.com/media/GuQ3TCFWIAAhT-R?format=jpg&name=small)

## Research on AI 

Christian Simon

Hi, my name is Christian Simon and I grew up in Indonesia with lovely people and cultures.
Currently, I am a machine learning and audio-visual researcher, and my research problems focus on multi-modal learning for discriminative and generative models, also did meta-learning, life-long learning, and continual-learning in the past. 


- Email : u6562565@anu.edu.au  
- [Google Scholar](https://scholar.google.com/citations?user=eZrRbp4AAAAJ&hl=en)


## News
- July 2025: Our paper with a title "CC-Stereo: Audio-Visual Contextual and Contrastive Learning for Binaural Audio Generation" has been accepted to ACMMM2025. Congratulations Yuanhong!
- June 2025: Our paper with a title "TITAN-Guide: Taming Inference-Time Alignment for Guided Text-to-Video Diffusion Models" has been accepted to ICCV2025. We could more efficiently guide video diffusion process with managable memory requirements!
- January 2025: Our paper with a title "Mining your own secrets: Diffusion classifier scores for continual personalization of text-to-image diffusion models" has been accepted to ICLR2025. Congratulations Saurav!
- January 2024: Our paper with a title "FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing" has been accepted to ICLR2024. Congratulations Yuren!
- October 2023: Our paper with a title "On Manipulating Scene Text in the Wild with Diffusion Models" has been accepted to WACV2024. Congratulations Joshua! 
- September 2022: Our CVPR 2021 paper with a title "On learning the geodesic path for incremental learning" won the Scientific Paper Challenge 2022 organized by Dolby Australia. 
- July 2022: You can call me Dr. Christian Simon now :)
- June 2022: Our team (ORBITRON) won the few-shot learning competition in the [VizWiz](https://vizwiz.org/workshops/2022-workshop/) workshop. See the leaderboard of the ORBIT Few-Shot Object Recognition Challenge [HERE](https://eval.ai/web/challenges/challenge-page/1438/leaderboard/3580). You can check our published code [HERE](https://github.com/chrysts/ORBITRON_Team_ORBIT_Challenge) and video presentation [HERE](https://www.youtube.com/watch?v=yfc7qI83eFY&t=249s).
- March 2022: One paper is accepted to CVPR 2022, thanks to all co-authors and reviewers!  



## Publications

### Journals
- [<b>Reflection removal under fast forward camera motion</b>](https://ieeexplore.ieee.org/document/8024024)<br/>
[[pdf]](http://image.inha.ac.kr/wp-content/uploads/2017/07/TIP2017Cheong.pdf)<br/>
J.Y. Cheong, <b>C. Simon</b>, C. S. Kim, and I. K. Park<br/>
<b>IEEE Transaction on Image Processing (TIP), 2018.</b>

-  [<b>Correcting geometric and photometric distortion of document images on a smartphone</b>](https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-24/issue-01/013038/Correcting-geometric-and-photometric-distortion-of-document-images-on-a/10.1117/1.JEI.24.1.013038.full)<br/>
[[pdf]](http://image.inha.ac.kr/paper/JEI201501_Simon.pdf)<br/>
 <b>C. Simon</b>, Williem, and I. K. Park<br/>
<b>Journal of Electronic Imaging (JEI), 2015.</b>

### Conferences

- [<b>TITAN-Guide: Taming Inference-Time Alignment for Guided Text-to-Video Diffusion Models</b>]()    <br/>
 (PDF coming soon!)<br/>
<b> C. Simon, M. Ishii, A. Hayakawa, Z. Zhong , S. Takahashi, T. Shibuya, Y. Mitsufuji<br/>
<b>International Conference on Computer Vision (ICCV), 2025. </b> <br/><img src=""  height="150px" width="190px" />

- [<b>CC-Stereo: Audio-Visual Contextual and Contrastive Learning for Binaural Audio Generation</b>]()    <br/>
[[pdf]](https://arxiv.org/abs/2501.02786)<br/>
<b> Y. Chen, K. Shimada, C. Simon, Y. Ikemiya, T. Shibuya, Y. Mitsufuji<br/>
<b>ACM International Conference on Multimedia (ACM MM), 2025. </b> <br/><img src=""  height="150px" width="190px" />

- [<b>Mining your own secrets: Diffusion classifier scores for continual personalization of text-to-image diffusion models</b>](https://arxiv.org/abs/2410.00700)    <br/>
[[pdf]](https://arxiv.org/pdf/2410.00700.pdf)<br/>
<b>S. Jha, S. Yang, M. Ishii, M. Zhao, C. Simon, M. J. Mirza, D. Gong, L. Yao, S. Takahashi, Y. Mitsufuji<br/>
<b>International Conference on Learning Representations (ICLR), 2025. </b> <br/><img src=""  height="150px" width="190px" />

- [<b>On FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing</b>](https://arxiv.org/abs/2310.05922)    <br/>
[[pdf]](https://arxiv.org/pdf/2310.05922.pdf)<br/>
<b>Y Cong, M Xu, C. Simon, S Chen, J Ren, Y Xie, JM Perez-Rua,..., T. Xiang, S. He<br/>
<b>International Conference on Learning Representations (ICLR), 2024. </b> <br/><img src="https://flatten-video-editing.github.io/static/images/framework.png?raw=true"  height="150px" width="190px" />

- [<b>On Manipulating Scene Text in the Wild with Diffusion Models</b>](https://arxiv.org/abs/2311.00734)    <br/>
[[pdf]](https://arxiv.org/pdf/2311.00734.pdf)<br/>
<b>J. Santoso, C. Simon, and Williem<br/>
<b>IEEE Conference on Computer Vision and Pattern Recognition (WACV), 2024. </b> <br/><img src="https://github.com/chrysts/chrysts.github.io/blob/master/images/ondomain_gen.png?raw=true"  height="150px" width="190px" />

- [<b>On Generalizing Beyond Domains in Cross-Domain Continual Learning</b>](https://openaccess.thecvf.com/content/CVPR2022/html/Simon_On_Generalizing_Beyond_Domains_in_Cross-Domain_Continual_Learning_CVPR_2022_paper.html)    <br/>
[[pdf]](https://openaccess.thecvf.com/content/CVPR2022/papers/Simon_On_Generalizing_Beyond_Domains_in_Cross-Domain_Continual_Learning_CVPR_2022_paper.pdf)<br/>
<b>C. Simon, M. Faraki, Y.-H. Tsai, X. Yu, S. Schulter, Y. Suh, M. Harandi, and M. Chandraker<br/>
<b>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022. </b> <br/><img src="https://github.com/chrysts/chrysts.github.io/blob/master/images/ondomain_gen.png?raw=true"  height="150px" width="190px" />

- [<b>Meta-Learning for Multi-Label Few-Shot Classification</b>](https://openaccess.thecvf.com/content/WACV2022/html/Simon_Meta-Learning_for_Multi-Label_Few-Shot_Classification_WACV_2022_paper.html)     <br/>
[[pdf]](https://openaccess.thecvf.com/content/WACV2022/papers/Simon_Meta-Learning_for_Multi-Label_Few-Shot_Classification_WACV_2022_paper.pdf)<br/>
<b>C. Simon</b>, P. Koniusz,  and M. Harandi <br/>
<b>IEEE Winter Conference on Applications of Computer Vision  (WACV), 2022. </b> <br/><img src="https://github.com/chrysts/chrysts.github.io/blob/master/images/multilabel_metalearning.png?raw=true"  height="150px" width="260px" />

- [<b>Towards a Robust Differentiable Architecture Search under Label Noise</b>](https://openaccess.thecvf.com/content/WACV2022/html/Simon_Towards_a_Robust_Differentiable_Architecture_Search_Under_Label_Noise_WACV_2022_paper.html)    <br/>
[[pdf]](https://openaccess.thecvf.com/content/WACV2022/papers/Simon_Towards_a_Robust_Differentiable_Architecture_Search_Under_Label_Noise_WACV_2022_paper.pdf)<br/>
<b>C. Simon</b>, P. Koniusz,  and M. Harandi <br/>
<b>IEEE Winter Conference on Applications of Computer Vision  (WACV), 2022. </b> <br/><img src="https://github.com/chrysts/chrysts.github.io/blob/master/images/NAS_noisylabels.png?raw=true"  height="110px" width="170px" />


- [<b>On learning the geodesic path for incremental learning</b>](https://arxiv.org/abs/2104.08572) <span color="blue">(oral)</span>   <br/>
[[pdf]](https://arxiv.org/abs/2104.08572.pdf)<br/>
<b>C. Simon</b>, P. Koniusz,  and M. Harandi <br/>
<b>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021. </b> <br/><img src="https://github.com/chrysts/chrysts.github.io/blob/master/images/geodl.png?raw=true"  height="130px" width="190px" />

- [<b>Reinforced attention for few-shot learning and beyond</b>](https://arxiv.org/pdf/2104.04192)<br/>
[[pdf]](https://arxiv.org/pdf/2104.04192.pdf)<br/>
J. Hong, P. Fang, W. Li, T. Zhang, <b>C. Simon</b>, M. Harandi, and L. Petersson<br/>
<b>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021. </b> <br/><img src="https://github.com/chrysts/chrysts.github.io/blob/master/images/reinfoced_attention.png?raw=true"  height="100px" width="250px" />


- [<b>On modulating the gradient for meta-learning</b>](https://link.springer.com/chapter/10.1007%2F978-3-030-58598-3_33)<br/>
[[pdf]](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123530545.pdf) [[Supp. Mat.]](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123530545-supp.pdf)<br/>
<b>C. Simon</b>, P. Koniusz, R. Nock, and M. Harandi <br/>
<b>European Conference on Computer Vision (ECCV), 2020. </b> <br/><img src="https://github.com/chrysts/chrysts.github.io/blob/master/images/diagram_mlgrad.png?raw=true"  height="70px" width="250px" />

- [<b>Adaptive subspaces for few-shot learning</b> ](https://openaccess.thecvf.com/content_CVPR_2020/html/Simon_Adaptive_Subspaces_for_Few-Shot_Learning_CVPR_2020_paper.html)<br/>
[[pdf]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Simon_Adaptive_Subspaces_for_Few-Shot_Learning_CVPR_2020_paper.pdf) [[Supp. Mat.]](https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Simon_Adaptive_Subspaces_for_CVPR_2020_supplemental.pdf)<br/>
<b>C. Simon</b>, P. Koniusz, R. Nock, and M. Harandi<br/>
<b>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020.</b> <br/><img src="https://raw.githubusercontent.com/chrysts/chrysts.github.io/master/images/psn.jpg?raw=true"  height="85px" width="270px" /> 



- [<b>Reflection removal for in-vehicle black box videos</b>](https://openaccess.thecvf.com/content_cvpr_2015/html/Simon_Reflection_Removal_for_2015_CVPR_paper.html) <br/>
[[pdf]](http://image.inha.ac.kr/paper/CVPR2015_Simon.pdf) [[Video]](https://drive.google.com/file/d/1JhZSohA7ty1WxzSJEnwwoll4RdtIsS5X/view?usp=sharing) <br/>
<b>C. Simon</b> and I. K. Park <br/>
<b>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.</b> <br/><img src="https://raw.githubusercontent.com/chrysts/chrysts.github.io/master/images/cvpr2015reflection.png?raw=true"  height="170px" width="210px" /> 

## Awards
- The winner of Dolby Australia Scientific Paper Competition 2022.
- The winner of the ORBIT Few-Shot Object Recognition Challenge 2022 (Vizwiz workshop).
- Outstanding Reviewer ICML 2022 
- Outstanding Reviewer ICLR 2021 
- Outstanding Reviewer ICCV 2019 [URL](http://iccv2019.thecvf.com/best_reviewers)


## Teaching Assistant:
- COMP4670/8600 [Statistical Machine Learning](https://machlearn.gitlab.io/sml2020/) - ANU
- ENG6528 Computer Vision - ANU

## Services 
### Program Committee / Reviewer:
- ICLR
- Neurips
- CVPR
- ICCV
- WACV
- AAAI
- TIP
- ICML
- BMVC


